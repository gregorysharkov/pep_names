{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import datetime as datetime\r\n",
    "import tensorflow as tf\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\r\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
    "from tensorflow.keras.utils import to_categorical\r\n",
    "from inner_model_settings import InnerModelSettings\r\n",
    "from char_level_rnn_with_attention import OuterModel\r\n",
    "\r\n",
    "# Load the TensorBoard notebook extension\r\n",
    "%load_ext tensorboard\r\n",
    "\r\n",
    "np.set_printoptions(precision=4)\r\n",
    "\r\n",
    "path = \"data\\\\combinations\\\\\"\r\n",
    "true_data = pd.read_csv(path+\"governors_true_match.csv\",sep=\";\")\r\n",
    "false_data = pd.read_csv(path+\"governors_false_match.csv\",sep=\";\")\r\n",
    "combined_data = pd.concat([true_data,false_data])\r\n",
    "combined_data = combined_data.sample(frac=1,random_state=20210826)\r\n",
    "names = sorted(set(list(combined_data.governor) + list(combined_data.combinations)))\r\n",
    "words = sorted(set(word for name in list(map(str.split,names)) for word in name))\r\n",
    "vocab = sorted(set(character for word in words for character in word))\r\n",
    "\r\n",
    "governors_list = list(combined_data.governor)\r\n",
    "combination_list = list(combined_data.combinations)\r\n",
    "match = list(combined_data.match)\r\n",
    "\r\n",
    "tk = Tokenizer(num_words=None, char_level=True, oov_token=\"UNK\")\r\n",
    "tk.fit_on_texts(governors_list+combination_list)\r\n",
    "\r\n",
    "def preprocess_list(lst,tokenizer,max_len=None):\r\n",
    "    return_seq = tokenizer.texts_to_sequences(lst)\r\n",
    "    return np.array(pad_sequences(return_seq, maxlen=max_len,padding=\"post\"),dtype=\"float32\")\r\n",
    "\r\n",
    "governor_seq = preprocess_list(governors_list,tk,30)\r\n",
    "combination_seq = preprocess_list(combination_list,tk,30)\r\n",
    "#features = zip(governor_seq,combination_seq)\r\n",
    "match_seq = np.array(match)\r\n",
    "\r\n",
    "#let's crate the training dataset and do the splits\r\n",
    "data = tf.data.Dataset.from_tensor_slices(((governor_seq,combination_seq),match_seq)).shuffle(10).batch(1000)\r\n",
    "train_ratio = .6\r\n",
    "val_ratio = .2\r\n",
    "test_ratio = .2\r\n",
    "\r\n",
    "train_batches = int(len(data) * train_ratio)\r\n",
    "val_batches = int(len(data) * val_ratio)\r\n",
    "test_batches = int(len(data) * test_ratio)\r\n",
    "\r\n",
    "train_data = data.take(train_batches)\r\n",
    "test_data = data.skip(train_batches)\r\n",
    "val_data = test_data.take(val_batches)\r\n",
    "test_data = test_data.skip(test_batches)\r\n",
    "\r\n",
    "settings = InnerModelSettings(\r\n",
    "    input_embedding=129,\r\n",
    "    n_embedding_dims = 512,\r\n",
    "    n_gru = 20,\r\n",
    "    n_dense = 40,\r\n",
    "    n_units_attention=20\r\n",
    ")\r\n",
    "\r\n",
    "model = OuterModel(settings)\r\n",
    "\r\n",
    "model.compile(\r\n",
    "    loss= tf.losses.BinaryCrossentropy(), #  contrastive_loss#tf.keras.losses.MeanSquaredError(),\r\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-3),\r\n",
    "    metrics=['accuracy'],\r\n",
    ")\r\n",
    "\r\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\r\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\r\n",
    "\r\n",
    "model.fit(\r\n",
    "    train_data,\r\n",
    "    batch_size = 300,\r\n",
    "    epochs = 20,\r\n",
    "    validation_data = val_data,\r\n",
    "    verbose=1,\r\n",
    "    callbacks=[tensorboard_callback]\r\n",
    ")\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "129\n",
      "Epoch 1/20\n",
      "184/184 [==============================] - 63s 257ms/step - loss: 0.8336 - accuracy: 0.3548 - val_loss: 0.8379 - val_accuracy: 0.3507\n",
      "Epoch 2/20\n",
      "184/184 [==============================] - 41s 222ms/step - loss: 0.7396 - accuracy: 0.3845 - val_loss: 0.7201 - val_accuracy: 0.3981\n",
      "Epoch 3/20\n",
      "184/184 [==============================] - 41s 223ms/step - loss: 0.6748 - accuracy: 0.4782 - val_loss: 0.6560 - val_accuracy: 0.5250\n",
      "Epoch 4/20\n",
      "184/184 [==============================] - 41s 223ms/step - loss: 0.6305 - accuracy: 0.6308 - val_loss: 0.6169 - val_accuracy: 0.7021\n",
      "Epoch 5/20\n",
      "184/184 [==============================] - 42s 228ms/step - loss: 0.6015 - accuracy: 0.7801 - val_loss: 0.5927 - val_accuracy: 0.8311\n",
      "Epoch 6/20\n",
      "184/184 [==============================] - 42s 229ms/step - loss: 0.5824 - accuracy: 0.8797 - val_loss: 0.5767 - val_accuracy: 0.9036\n",
      "Epoch 7/20\n",
      "184/184 [==============================] - 42s 229ms/step - loss: 0.5688 - accuracy: 0.9301 - val_loss: 0.5642 - val_accuracy: 0.9376\n",
      "Epoch 8/20\n",
      "184/184 [==============================] - 42s 228ms/step - loss: 0.5578 - accuracy: 0.9515 - val_loss: 0.5533 - val_accuracy: 0.9532\n",
      "Epoch 9/20\n",
      "184/184 [==============================] - 42s 228ms/step - loss: 0.5475 - accuracy: 0.9592 - val_loss: 0.5433 - val_accuracy: 0.9593\n",
      "Epoch 10/20\n",
      "184/184 [==============================] - 42s 230ms/step - loss: 0.5372 - accuracy: 0.9627 - val_loss: 0.5328 - val_accuracy: 0.9616\n",
      "Epoch 11/20\n",
      "184/184 [==============================] - 42s 229ms/step - loss: 0.5267 - accuracy: 0.9637 - val_loss: 0.5223 - val_accuracy: 0.9633\n",
      "Epoch 12/20\n",
      "184/184 [==============================] - 42s 229ms/step - loss: 0.5157 - accuracy: 0.9646 - val_loss: 0.5117 - val_accuracy: 0.9650\n",
      "Epoch 13/20\n",
      "184/184 [==============================] - 42s 229ms/step - loss: 0.5045 - accuracy: 0.9653 - val_loss: 0.5008 - val_accuracy: 0.9647\n",
      "Epoch 14/20\n",
      "184/184 [==============================] - 42s 229ms/step - loss: 0.4929 - accuracy: 0.9654 - val_loss: 0.4899 - val_accuracy: 0.9638\n",
      "Epoch 15/20\n",
      "184/184 [==============================] - 42s 230ms/step - loss: 0.4813 - accuracy: 0.9651 - val_loss: 0.4787 - val_accuracy: 0.9625\n",
      "Epoch 16/20\n",
      "184/184 [==============================] - 43s 231ms/step - loss: 0.4696 - accuracy: 0.9650 - val_loss: 0.4670 - val_accuracy: 0.9622\n",
      "Epoch 17/20\n",
      "184/184 [==============================] - 42s 230ms/step - loss: 0.4579 - accuracy: 0.9647 - val_loss: 0.4563 - val_accuracy: 0.9626\n",
      "Epoch 18/20\n",
      "184/184 [==============================] - 42s 229ms/step - loss: 0.4462 - accuracy: 0.9649 - val_loss: 0.4447 - val_accuracy: 0.9633\n",
      "Epoch 19/20\n",
      "184/184 [==============================] - 43s 232ms/step - loss: 0.4344 - accuracy: 0.9657 - val_loss: 0.4330 - val_accuracy: 0.9629\n",
      "Epoch 20/20\n",
      "184/184 [==============================] - 43s 234ms/step - loss: 0.4228 - accuracy: 0.9662 - val_loss: 0.4222 - val_accuracy: 0.9621\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ae85446250>"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"outer_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inner_model (InnerModel)     multiple                  727893    \n",
      "_________________________________________________________________\n",
      "distance_layer (DistanceLaye multiple                  0         \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         multiple                  2         \n",
      "=================================================================\n",
      "Total params: 727,895\n",
      "Trainable params: 727,815\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def compare_representations(input_a, input_b, model, debug=False):\r\n",
    "    outer_model = model\r\n",
    "    prediction = outer_model((input_a.reshape(-1,len(input_a)),input_b.reshape(-1,len(input_b))))\r\n",
    "\r\n",
    "    if debug:\r\n",
    "        print(f\"Representation of A: {outer_model.repr_a}\")\r\n",
    "        print(f\"Representation of B: {outer_model.repr_b}\")\r\n",
    "        print(f\"Similarity: {outer_model.cosine_similarity}\")\r\n",
    "        print(f\"Prediction: {prediction}\")\r\n",
    "\r\n",
    "\r\n",
    "    return outer_model.cosine_similarity, (outer_model.repr_a,outer_model.repr_a)\r\n",
    "\r\n",
    "print(f\"Comparing '{governors_list[0]}' and '{combination_list[0]}'\")\r\n",
    "similarity, representations = compare_representations(\r\n",
    "    governor_seq[0],\r\n",
    "    combination_seq[0],\r\n",
    "    model,\r\n",
    "    True\r\n",
    ")\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Comparing 'john rettie mckernan' and 'john buchanan floyd jr.'\n",
      "Representation of A: [[ 0.8674 -6.1858  4.8685 -1.9147  1.6986  1.8509  1.8745 -1.0356 -0.1129\n",
      "  -2.0776 -4.3491  1.0919 -0.6496 -0.3684  1.2532  1.2199  1.1634 -1.1604\n",
      "   0.5337 -0.5276  0.1486 -1.9767  2.5101 -2.5289  0.5651 -1.8487  0.4152\n",
      "   3.8067  1.7839 -1.9458 -0.4948 -1.1107 -1.1188 -0.4179  4.8243 -2.2412\n",
      "  -1.6235  1.3415 -1.8619 -3.8958]]\n",
      "Representation of B: [[ 3.3576 -0.7466  1.5876  3.8162  0.1318  0.1331 -0.2415 -0.6138  0.7842\n",
      "   3.324  -0.268  -0.3962  0.5021 -1.6907 -0.5371 -0.9184  2.4868 -2.3214\n",
      "   0.227   3.2165 -0.2596 -2.8404 -0.7695  0.8727 -2.0781 -0.3078  3.0882\n",
      "  -1.6449  0.4179  3.5207 -0.1412  1.3492  0.6924  0.5781 -2.2259  3.1614\n",
      "  -0.3006 -1.8464  2.4818 -3.4103]]\n",
      "Similarity: [0.4449]\n",
      "Prediction: [[0.2607]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "\r\n",
    "print(f\"Comparing '{governors_list[0]}' and '{combination_list[1]}'\")\r\n",
    "similarity, representations = compare_representations(\r\n",
    "    governor_seq[0],\r\n",
    "    combination_seq[1],\r\n",
    "    model,\r\n",
    "    True\r\n",
    ")\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Comparing 'john rettie mckernan' and 'william prentice cooper'\n",
      "Representation of A: [[ 0.8674 -6.1858  4.8685 -1.9147  1.6986  1.8509  1.8745 -1.0356 -0.1129\n",
      "  -2.0776 -4.3491  1.0919 -0.6496 -0.3684  1.2532  1.2199  1.1634 -1.1604\n",
      "   0.5337 -0.5276  0.1486 -1.9767  2.5101 -2.5289  0.5651 -1.8487  0.4152\n",
      "   3.8067  1.7839 -1.9458 -0.4948 -1.1107 -1.1188 -0.4179  4.8243 -2.2412\n",
      "  -1.6235  1.3415 -1.8619 -3.8958]]\n",
      "Representation of B: [[ 0.3364  4.5002 -0.8029  1.3502  1.7989  0.9568 -0.6449  1.2382  2.9128\n",
      "   1.252  -1.4092 -4.1453  5.2748  1.8497  0.529   1.979  -0.7897  0.7117\n",
      "   1.9742 -0.3601 -1.0188  1.6629 -2.446  -0.2847  1.7126 -4.3798  1.4753\n",
      "  -6.2442 -1.7403  2.4    -2.1982 -1.3289  2.9443 -2.7094 -0.9545  0.4636\n",
      "   2.2679  2.3682  1.4851  3.533 ]]\n",
      "Similarity: [0.2982]\n",
      "Prediction: [[0.1919]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "source": [
    "def text_from_ids(ids,dict=tk.word_index):\r\n",
    "    inv_dict = {v: k for k,v in tk.word_index.items()}\r\n",
    "    char_list = []\r\n",
    "    for id in ids:\r\n",
    "        if id not in inv_dict:\r\n",
    "            char = \"_\"\r\n",
    "        else:\r\n",
    "            char = inv_dict[id]\r\n",
    "        char_list.append(char)\r\n",
    "\r\n",
    "    return(\"\".join(char_list))\r\n",
    "\r\n",
    "print(text_from_ids(governor_seq[0]))\r\n",
    "print(text_from_ids(combination_seq[1]))\r\n",
    "\r\n",
    "print(governor_seq[0])\r\n",
    "print(combination_seq[1])\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "john rettie mckernan__________\n",
      "william prentice cooper_______\n",
      "[15.  8. 11.  5.  2.  6.  3. 13. 13.  9.  3.  2. 12. 16. 22.  3.  6.  5.\n",
      "  4.  5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[17.  9.  7.  7.  9.  4. 12.  2. 23.  6.  3.  5. 13.  9. 16.  3.  2. 16.\n",
      "  8.  8. 23.  3.  6.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "my_test = [\"Bill Gates\",\"William Gates\"]\r\n",
    "my_test_seq = preprocess_list(my_test, tk)\r\n",
    "\r\n",
    "print(f\"Comparing '{my_test[0]}' and '{my_test[1]}'\")\r\n",
    "similarity, representations = compare_representations(\r\n",
    "    my_test_seq[0],\r\n",
    "    my_test_seq[1],\r\n",
    "    model,\r\n",
    "    True\r\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Comparing 'Bill Gates' and 'William Gates'\n",
      "Representation of A: [[ 0.4596  2.4613 -0.5936  0.6842 -2.9203 -0.0601 -2.0932  1.1284  2.2899\n",
      "   0.987  -0.4173 -0.3512 -0.1351 -2.347  -0.2694  0.6359  1.8277  0.217\n",
      "   1.1724  0.0969  0.6374 -1.8048 -2.1177  1.9259 -1.3221 -0.7982 -1.9583\n",
      "  -0.7548 -0.3978 -0.4425  0.5748  1.8815  0.0237 -0.2836 -1.8876  2.2975\n",
      "   0.2424 -2.1712  0.4969  0.9343]]\n",
      "Representation of B: [[ 1.0078  1.8658 -1.2906 -0.1399 -3.0878 -1.5324 -1.8868 -0.5068  0.5574\n",
      "   1.0118 -0.0263 -0.2501 -1.2824 -1.0783  0.2446  0.1768  0.1873  0.8583\n",
      "   1.1905  0.0886 -0.1217  0.1591 -1.1312  1.7443  0.5922  0.9161 -1.8421\n",
      "   1.4797 -0.7518 -0.3403  2.0032  1.6788 -0.8301 -0.4548 -1.3197  1.8719\n",
      "  -0.5245 -1.7326  0.7616  0.7881]]\n",
      "Similarity: [0.8624]\n",
      "Prediction: [[0.5203]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def check_similarity(string_a, string_b, tokeniser, model, match=None, debug=False):\r\n",
    "    input_seq = preprocess_list([string_a,string_b],tokeniser,30)\r\n",
    "    input_seq = [x.reshape(1, len(x)) for x in input_seq]\r\n",
    "    prediction = model((input_seq[0],input_seq[1]))[0][0]\r\n",
    "\r\n",
    "    if debug:\r\n",
    "        print(\"********************************\")\r\n",
    "        print(f\"Comparing: '{string_a}' and '{string_a}'\")\r\n",
    "        print(f\"Cosine similarity = {model.cosine_similarity[0]:.4f}, prediction={prediction:.4f} true similarity = {match}\")\r\n",
    "    return np.round(model.cosine_similarity[0],4)\r\n",
    "\r\n",
    "for i in range(50):\r\n",
    "    check_similarity(governors_list[i],combination_list[i],tk, model,match[i],True)\r\n",
    "\r\n",
    "# predictions = []\r\n",
    "# for name_a, name_b, _match in zip(governors_list, combination_list, match):\r\n",
    "#     predictions.append(check_similarity(name_a,name_b,tk,model,_match,False))\r\n",
    "\r\n",
    "# print(predictions)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "********************************\n",
      "Comparing: 'john rettie mckernan' and 'john rettie mckernan'\n",
      "Cosine similarity = 0.4449, prediction=0.2607 true similarity = 0\n",
      "********************************\n",
      "Comparing: 'william j. janklow' and 'william j. janklow'\n",
      "Cosine similarity = 0.4264, prediction=0.2511 true similarity = 0\n",
      "********************************\n",
      "Comparing: 'william henry seward' and 'william henry seward'\n",
      "Cosine similarity = 0.4757, prediction=0.2769 true similarity = 0\n",
      "********************************\n",
      "Comparing: 'stevens thomson mason' and 'stevens thomson mason'\n",
      "Cosine similarity = 0.9945, prediction=0.6076 true similarity = 1\n",
      "********************************\n",
      "Comparing: 'william pinkney whyte' and 'william pinkney whyte'\n",
      "Cosine similarity = 0.4730, prediction=0.2755 true similarity = 0\n",
      "********************************\n",
      "Comparing: 'john larue helm' and 'john larue helm'\n",
      "Cosine similarity = 0.3576, prediction=0.2180 true similarity = 0\n",
      "********************************\n",
      "Comparing: 'william burton' and 'william burton'\n",
      "Cosine similarity = 0.7992, prediction=0.4778 true similarity = 0\n",
      "********************************\n",
      "Comparing: 'richard yates sr.' and 'richard yates sr.'\n",
      "Cosine similarity = 0.3753, prediction=0.2262 true similarity = 0\n",
      "********************************\n",
      "Comparing: 'asa smith bushnell' and 'asa smith bushnell'\n",
      "Cosine similarity = 0.9978, prediction=0.6097 true similarity = 1\n",
      "********************************\n",
      "Comparing: 'ebenezer sumner draper' and 'ebenezer sumner draper'\n",
      "Cosine similarity = 0.9969, prediction=0.6091 true similarity = 1\n",
      "********************************\n",
      "Comparing: 'john tyler sr.' and 'john tyler sr.'\n",
      "Cosine similarity = 0.3292, prediction=0.2052 true similarity = 0\n",
      "********************************\n",
      "Comparing: 'william w. stickney' and 'william w. stickney'\n",
      "Cosine similarity = 0.3697, prediction=0.2235 true similarity = 0\n",
      "********************************\n",
      "Comparing: 'william pettus hobby' and 'william pettus hobby'\n",
      "Cosine similarity = 0.5410, prediction=0.3135 true similarity = 0\n",
      "********************************\n",
      "Comparing: 'charles henry hardin' and 'charles henry hardin'\n",
      "Cosine similarity = 0.5723, prediction=0.3319 true similarity = 0\n",
      "********************************\n",
      "Comparing: 'james mcdowell' and 'james mcdowell'\n",
      "Cosine similarity = 0.3519, prediction=0.2153 true similarity = 0\n",
      "********************************\n",
      "Comparing: 'william eugene stanley' and 'william eugene stanley'\n",
      "Cosine similarity = 0.5354, prediction=0.3102 true similarity = 0\n",
      "********************************\n",
      "Comparing: 'thomas chipman mcrae' and 'thomas chipman mcrae'\n",
      "Cosine similarity = 0.6947, prediction=0.4085 true similarity = 0\n",
      "********************************\n",
      "Comparing: 'cornelius p. van ness' and 'cornelius p. van ness'\n",
      "Cosine similarity = 0.9938, prediction=0.6071 true similarity = 1\n",
      "********************************\n",
      "Comparing: 'john hubbard chafee' and 'john hubbard chafee'\n",
      "Cosine similarity = 0.3448, prediction=0.2121 true similarity = 0\n",
      "********************************\n",
      "Comparing: 'william a. o’neill' and 'william a. o’neill'\n",
      "Cosine similarity = 0.2937, prediction=0.1900 true similarity = 0\n",
      "********************************\n",
      "Comparing: 'henry howland crapo' and 'henry howland crapo'\n",
      "Cosine similarity = 0.6377, prediction=0.3720 true similarity = 0\n",
      "********************************\n",
      "Comparing: 'james edwin campbell' and 'james edwin campbell'\n",
      "Cosine similarity = 0.4174, prediction=0.2466 true similarity = 0\n",
      "********************************\n",
      "Comparing: 'william hendricks' and 'william hendricks'\n",
      "Cosine similarity = 0.3668, prediction=0.2222 true similarity = 0\n",
      "********************************\n",
      "Comparing: 'john henry bartlett' and 'john henry bartlett'\n",
      "Cosine similarity = 0.4687, prediction=0.2732 true similarity = 0\n",
      "********************************\n",
      "Comparing: 'george edward lounsbury' and 'george edward lounsbury'\n",
      "Cosine similarity = 0.4927, prediction=0.2862 true similarity = 0\n",
      "********************************\n",
      "Comparing: 'william lloyd harding' and 'william lloyd harding'\n",
      "Cosine similarity = 0.5518, prediction=0.3197 true similarity = 0\n",
      "********************************\n",
      "Comparing: 'george kilbon nash' and 'george kilbon nash'\n",
      "Cosine similarity = 0.3923, prediction=0.2343 true similarity = 0\n",
      "********************************\n",
      "Comparing: 'john eugene osborne' and 'john eugene osborne'\n",
      "Cosine similarity = 0.5848, prediction=0.3394 true similarity = 0\n",
      "********************************\n",
      "Comparing: 'john hubbard' and 'john hubbard'\n",
      "Cosine similarity = 0.4624, prediction=0.2698 true similarity = 0\n",
      "********************************\n",
      "Comparing: 'christopher gore' and 'christopher gore'\n",
      "Cosine similarity = 0.9847, prediction=0.6013 true similarity = 1\n",
      "********************************\n",
      "Comparing: 'william du hamel denney' and 'william du hamel denney'\n",
      "Cosine similarity = 0.9981, prediction=0.6099 true similarity = 1\n",
      "********************************\n",
      "Comparing: 'howard m. gore' and 'howard m. gore'\n",
      "Cosine similarity = 0.9897, prediction=0.6045 true similarity = 1\n",
      "********************************\n",
      "Comparing: 'paul burney johnson, sr.' and 'paul burney johnson, sr.'\n",
      "Cosine similarity = 0.9995, prediction=0.6108 true similarity = 1\n",
      "********************************\n",
      "Comparing: 'john benjamin kendrick' and 'john benjamin kendrick'\n",
      "Cosine similarity = 0.5772, prediction=0.3348 true similarity = 0\n",
      "********************************\n",
      "Comparing: 'louis jefferson brann' and 'louis jefferson brann'\n",
      "Cosine similarity = 0.9953, prediction=0.6081 true similarity = 1\n",
      "********************************\n",
      "Comparing: 'john henry stelle' and 'john henry stelle'\n",
      "Cosine similarity = 0.6429, prediction=0.3753 true similarity = 0\n",
      "********************************\n",
      "Comparing: 'james turner morehead' and 'james turner morehead'\n",
      "Cosine similarity = 0.5237, prediction=0.3035 true similarity = 0\n",
      "********************************\n",
      "Comparing: 'thomas nelson' and 'thomas nelson'\n",
      "Cosine similarity = 0.4535, prediction=0.2651 true similarity = 0\n",
      "********************************\n",
      "Comparing: 'frank robert gooding' and 'frank robert gooding'\n",
      "Cosine similarity = 0.6935, prediction=0.4077 true similarity = 0\n",
      "********************************\n",
      "Comparing: 'john harte mcgraw' and 'john harte mcgraw'\n",
      "Cosine similarity = 0.5742, prediction=0.3330 true similarity = 0\n",
      "********************************\n",
      "Comparing: 'john gill shorter' and 'john gill shorter'\n",
      "Cosine similarity = 0.4275, prediction=0.2517 true similarity = 0\n",
      "********************************\n",
      "Comparing: 'william allen egan' and 'william allen egan'\n",
      "Cosine similarity = 0.9971, prediction=0.6092 true similarity = 1\n",
      "********************************\n",
      "Comparing: 'john butler smith' and 'john butler smith'\n",
      "Cosine similarity = 0.3497, prediction=0.2143 true similarity = 0\n",
      "********************************\n",
      "Comparing: 'calvin lewellyn rampton' and 'calvin lewellyn rampton'\n",
      "Cosine similarity = 0.7846, prediction=0.4680 true similarity = 0\n",
      "********************************\n",
      "Comparing: 'john hathaway reed' and 'john hathaway reed'\n",
      "Cosine similarity = 0.5588, prediction=0.3239 true similarity = 0\n",
      "********************************\n",
      "Comparing: 'john milton' and 'john milton'\n",
      "Cosine similarity = 0.2752, prediction=0.1825 true similarity = 0\n",
      "********************************\n",
      "Comparing: 'john tyler sr.' and 'john tyler sr.'\n",
      "Cosine similarity = 0.4553, prediction=0.2661 true similarity = 0\n",
      "********************************\n",
      "Comparing: 'john w. reynolds' and 'john w. reynolds'\n",
      "Cosine similarity = 0.9991, prediction=0.6105 true similarity = 1\n",
      "********************************\n",
      "Comparing: 'luis muñoz marín' and 'luis muñoz marín'\n",
      "Cosine similarity = 0.9793, prediction=0.5978 true similarity = 1\n",
      "********************************\n",
      "Comparing: 'george william smith' and 'george william smith'\n",
      "Cosine similarity = 0.9848, prediction=0.6013 true similarity = 1\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "source": [
    "set((list(val_data.as_numpy_iterator())[0][-1]))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{0}"
      ]
     },
     "metadata": {},
     "execution_count": 80
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "source": [
    "combined_data[combined_data.match==0].groupby([\"combinations\",\"governor\"]).count()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                           match\n",
       "combinations       governor                     \n",
       "aaron ogden        aaron thomas bliss          1\n",
       "                   aaron venable brown         1\n",
       "                   david ogden watkins         1\n",
       "                   samuel aaron baker          1\n",
       "aaron thomas bliss aaron ogden                 1\n",
       "...                                          ...\n",
       "zenas perry moody  edward alysworth perry      1\n",
       "                   madison starke perry        1\n",
       "                   moody currier               1\n",
       "                   oliver perry morton         1\n",
       "                   rick perry                  1\n",
       "\n",
       "[199616 rows x 1 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combinations</th>\n",
       "      <th>governor</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">aaron ogden</th>\n",
       "      <th>aaron thomas bliss</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaron venable brown</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>david ogden watkins</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samuel aaron baker</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaron thomas bliss</th>\n",
       "      <th>aaron ogden</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">zenas perry moody</th>\n",
       "      <th>edward alysworth perry</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>madison starke perry</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moody currier</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oliver perry morton</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rick perry</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199616 rows × 1 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 119
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "%matplotlib inline\r\n",
    "\r\n",
    "plt.figure(figsize=(10,6))\r\n",
    "plt.scatter(predictions,match)\r\n",
    "plt.xlabel(\"Predicted similarity\")\r\n",
    "plt.ylabel(\"Actual similarity\")\r\n",
    "plt.show()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('nlp_tensor': conda)"
  },
  "interpreter": {
   "hash": "fcbba280eac50286b31d8cb86df25696dcc42d5d7558ed290f125a3371417a84"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}