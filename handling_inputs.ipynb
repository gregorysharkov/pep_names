{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import datetime as datetime\r\n",
    "import tensorflow as tf\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\r\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
    "from tensorflow.keras.utils import to_categorical\r\n",
    "from inner_model_settings import InnerModelSettings\r\n",
    "from char_level_rnn_with_attention import OuterModel\r\n",
    "\r\n",
    "# Load the TensorBoard notebook extension\r\n",
    "%load_ext tensorboard\r\n",
    "\r\n",
    "np.set_printoptions(precision=4)\r\n",
    "\r\n",
    "path = \"data\\\\combinations\\\\\"\r\n",
    "true_data = pd.read_csv(path+\"governors_true_match.csv\",sep=\";\")\r\n",
    "false_data = pd.read_csv(path+\"governors_false_match.csv\",sep=\";\")\r\n",
    "combined_data = pd.concat([true_data,false_data])\r\n",
    "names = sorted(set(list(combined_data.governor) + list(combined_data.combinations)))\r\n",
    "words = sorted(set(word for name in list(map(str.split,names)) for word in name))\r\n",
    "vocab = sorted(set(character for word in words for character in word))\r\n",
    "\r\n",
    "governors_list = list(combined_data.governor)\r\n",
    "combination_list = list(combined_data.combinations)\r\n",
    "match = list(combined_data.match)\r\n",
    "\r\n",
    "tk = Tokenizer(num_words=None, char_level=True, oov_token=\"UNK\")\r\n",
    "tk.fit_on_texts(governors_list+combination_list)\r\n",
    "\r\n",
    "def preprocess_list(lst,tokenizer,max_len=None):\r\n",
    "    return_seq = tokenizer.texts_to_sequences(lst)\r\n",
    "    return np.array(pad_sequences(return_seq, maxlen=max_len,padding=\"post\"),dtype=\"float32\")\r\n",
    "\r\n",
    "governor_seq = preprocess_list(governors_list,tk,30)\r\n",
    "combination_seq = preprocess_list(combination_list,tk,30)\r\n",
    "#features = zip(governor_seq,combination_seq)\r\n",
    "match_seq = np.array(match)\r\n",
    "\r\n",
    "#let's crate the training dataset and do the splits\r\n",
    "data = tf.data.Dataset.from_tensor_slices(((governor_seq,combination_seq),match_seq)).shuffle(buffer_size=1).batch(1000)\r\n",
    "train_ratio = .6\r\n",
    "val_ratio = .2\r\n",
    "test_ratio = .2\r\n",
    "\r\n",
    "train_batches = int(len(data) * train_ratio)\r\n",
    "val_batches = int(len(data) * val_ratio)\r\n",
    "test_batches = int(len(data) * test_ratio)\r\n",
    "\r\n",
    "train_data = data.take(train_batches)\r\n",
    "test_data = data.skip(train_batches)\r\n",
    "val_data = test_data.take(val_batches)\r\n",
    "test_data = test_data.skip(test_batches)\r\n",
    "\r\n",
    "settings = InnerModelSettings(\r\n",
    "    input_embedding=129,\r\n",
    "    n_embedding_dims = 512,\r\n",
    "    n_gru = 20,\r\n",
    "    n_dense = 40,\r\n",
    "    n_units_attention=20\r\n",
    ")\r\n",
    "\r\n",
    "model = OuterModel(settings)\r\n",
    "\r\n",
    "model.compile(\r\n",
    "    loss= tf.losses.BinaryCrossentropy(), #  contrastive_loss#tf.keras.losses.MeanSquaredError(),\r\n",
    "    optimizer=tf.keras.optimizers.Adam(.0005),#optimizer=tf.keras.optimizers.Adam(1e-3),\r\n",
    "    metrics=['accuracy'],\r\n",
    ")\r\n",
    "\r\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\r\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\r\n",
    "\r\n",
    "model.fit(\r\n",
    "    train_data,\r\n",
    "    batch_size = 5000,\r\n",
    "    epochs = 15,\r\n",
    "    validation_data = val_data,\r\n",
    "    verbose=2,\r\n",
    "    callbacks=[tensorboard_callback]\r\n",
    ")\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n",
      "129\n",
      "Epoch 1/15\n",
      "184/184 - 65s - loss: 0.4340 - accuracy: 0.7632 - val_loss: 1.4162 - val_accuracy: 0.0641\n",
      "Epoch 2/15\n",
      "184/184 - 38s - loss: 0.4071 - accuracy: 0.7714 - val_loss: 1.1890 - val_accuracy: 0.1494\n",
      "Epoch 3/15\n",
      "184/184 - 38s - loss: 0.3954 - accuracy: 0.7719 - val_loss: 1.1080 - val_accuracy: 0.2033\n",
      "Epoch 4/15\n",
      "184/184 - 38s - loss: 0.3895 - accuracy: 0.7743 - val_loss: 0.8815 - val_accuracy: 0.3926\n",
      "Epoch 5/15\n",
      "184/184 - 38s - loss: 0.3826 - accuracy: 0.7771 - val_loss: 0.8536 - val_accuracy: 0.4214\n",
      "Epoch 6/15\n",
      "184/184 - 38s - loss: 0.3766 - accuracy: 0.7797 - val_loss: 0.8383 - val_accuracy: 0.4384\n",
      "Epoch 7/15\n",
      "184/184 - 39s - loss: 0.3719 - accuracy: 0.7801 - val_loss: 0.8358 - val_accuracy: 0.4378\n",
      "Epoch 8/15\n",
      "184/184 - 38s - loss: 0.3681 - accuracy: 0.7824 - val_loss: 0.8525 - val_accuracy: 0.4152\n",
      "Epoch 9/15\n",
      "184/184 - 38s - loss: 0.3652 - accuracy: 0.7839 - val_loss: 0.8512 - val_accuracy: 0.4140\n",
      "Epoch 10/15\n",
      "184/184 - 39s - loss: 0.3625 - accuracy: 0.7850 - val_loss: 0.8407 - val_accuracy: 0.4214\n",
      "Epoch 11/15\n",
      "184/184 - 39s - loss: 0.3600 - accuracy: 0.7864 - val_loss: 0.8324 - val_accuracy: 0.4316\n",
      "Epoch 12/15\n",
      "184/184 - 39s - loss: 0.3577 - accuracy: 0.7869 - val_loss: 0.8260 - val_accuracy: 0.4359\n",
      "Epoch 13/15\n",
      "184/184 - 38s - loss: 0.3555 - accuracy: 0.7869 - val_loss: 0.8278 - val_accuracy: 0.4331\n",
      "Epoch 14/15\n",
      "184/184 - 38s - loss: 0.3539 - accuracy: 0.7878 - val_loss: 0.8224 - val_accuracy: 0.4376\n",
      "Epoch 15/15\n",
      "184/184 - 38s - loss: 0.3522 - accuracy: 0.7896 - val_loss: 0.8181 - val_accuracy: 0.4409\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29245f7be50>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"outer_model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inner_model_2 (InnerModel)   multiple                  727893    \n",
      "_________________________________________________________________\n",
      "distance_layer_2 (DistanceLa multiple                  0         \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         multiple                  0 (unused)\n",
      "=================================================================\n",
      "Total params: 727,893\n",
      "Trainable params: 727,813\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "def compare_representations(input_a, input_b, model, debug=False):\r\n",
    "    outer_model = model\r\n",
    "    outer_model((input_a.reshape(-1,len(input_a)),input_b.reshape(-1,len(input_b))))\r\n",
    "\r\n",
    "    if debug:\r\n",
    "        print(f\"Representation of A: {outer_model.repr_a}\")\r\n",
    "        print(f\"Representation of B: {outer_model.repr_b}\")\r\n",
    "        print(f\"Similarity: {outer_model.cosine_similarity}\")\r\n",
    "\r\n",
    "    return outer_model.cosine_similarity, (outer_model.repr_a,outer_model.repr_a)\r\n",
    "\r\n",
    "print(f\"Comparing '{governors_list[0]}' and '{combination_list[0]}'\")\r\n",
    "similarity, representations = compare_representations(\r\n",
    "    governor_seq[0],\r\n",
    "    combination_seq[0],\r\n",
    "    model,\r\n",
    "    True\r\n",
    ")\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Comparing 'a.p. lutali' and 'a.p. lutali'\n",
      "[ 4. 25. 23. 25.  2.  7. 20. 13.  4.  7.  9.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 4. 25. 23. 25.  2.  7. 20. 13.  4.  7.  9.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "Representation of A: [[ 0.404   2.0065  2.9575 -0.1137 -1.0178  0.5598  0.3647 -1.7628  1.1018\n",
      "   3.4374 -1.4547  1.1885  0.5285 -0.6939  1.3511 -1.2471  2.2164  0.7676\n",
      "  -1.4943  0.7016  0.1359  1.3568 -2.3191 -2.0823  2.3083  0.0361  1.0941\n",
      "   1.0824  0.7116 -0.2978 -0.9097 -0.2465 -0.1202  2.3228  0.0617  1.3254\n",
      "  -0.2052 -0.8126  0.4394 -0.4793]]\n",
      "Representation of B: [[ 0.404   2.0065  2.9575 -0.1137 -1.0178  0.5598  0.3647 -1.7628  1.1018\n",
      "   3.4374 -1.4547  1.1885  0.5285 -0.6939  1.3511 -1.2471  2.2164  0.7676\n",
      "  -1.4943  0.7016  0.1359  1.3568 -2.3191 -2.0823  2.3083  0.0361  1.0941\n",
      "   1.0824  0.7116 -0.2978 -0.9097 -0.2465 -0.1202  2.3228  0.0617  1.3254\n",
      "  -0.2052 -0.8126  0.4394 -0.4793]]\n",
      "Similarity: [1.]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "\r\n",
    "print(f\"Comparing '{governors_list[0]}' and '{combination_list[1]}'\")\r\n",
    "similarity, representations = compare_representations(\r\n",
    "    governor_seq[0],\r\n",
    "    combination_seq[1],\r\n",
    "    model,\r\n",
    "    True\r\n",
    ")\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Comparing 'a.p. lutali' and 'lutali a.p.'\n",
      "Representation of A: [[ 0.404   2.0065  2.9575 -0.1137 -1.0178  0.5598  0.3647 -1.7628  1.1018\n",
      "   3.4374 -1.4547  1.1885  0.5285 -0.6939  1.3511 -1.2471  2.2164  0.7676\n",
      "  -1.4943  0.7016  0.1359  1.3568 -2.3191 -2.0823  2.3083  0.0361  1.0941\n",
      "   1.0824  0.7116 -0.2978 -0.9097 -0.2465 -0.1202  2.3228  0.0617  1.3254\n",
      "  -0.2052 -0.8126  0.4394 -0.4793]]\n",
      "Representation of B: [[ 0.4329  1.9469  2.4533  0.2115 -0.8506  0.1278  0.28   -1.5503  1.0698\n",
      "   2.2854 -1.0248  0.7821  0.4384 -0.8719  0.8447 -0.787   2.5411  0.5527\n",
      "  -1.4668  1.2208 -0.0376  1.5357 -1.6888 -1.5673  1.6692 -0.1066  0.6947\n",
      "   0.8363  0.3627 -0.777  -1.4921 -0.5233  0.0381  2.0118  0.3562  1.0246\n",
      "  -0.3303 -0.9044  0.5201 -0.0217]]\n",
      "Similarity: [0.9832]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def text_from_ids(ids,dict=tk.word_index):\r\n",
    "    inv_dict = {v: k for k,v in tk.word_index.items()}\r\n",
    "    char_list = []\r\n",
    "    for id in ids:\r\n",
    "        if id not in inv_dict:\r\n",
    "            char = \"_\"\r\n",
    "        else:\r\n",
    "            char = inv_dict[id]\r\n",
    "        char_list.append(char)\r\n",
    "\r\n",
    "    return(\"\".join(char_list))\r\n",
    "\r\n",
    "print(text_from_ids(governor_seq[0]))\r\n",
    "print(text_from_ids(combination_seq[1]))\r\n",
    "\r\n",
    "print(governor_seq[0])\r\n",
    "print(combination_seq[1])\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "a.p. lutali___________________\n",
      "lutali a.p.___________________\n",
      "[ 4. 25. 23. 25.  2.  7. 20. 13.  4.  7.  9.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 7. 20. 13.  4.  7.  9.  2.  4. 25. 23. 25.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "my_test = [\"Ekaterina Sharkova\",\"Ekaterina Charkova\"]\r\n",
    "my_test_seq = preprocess_list(my_test, tk)\r\n",
    "\r\n",
    "print(f\"Comparing '{my_test[0]}' and '{my_test[1]}'\")\r\n",
    "similarity, representations = compare_representations(\r\n",
    "    my_test_seq[0],\r\n",
    "    my_test_seq[1],\r\n",
    "    model,\r\n",
    "    True\r\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Comparing 'Ekaterina Sharkova' and 'Ekaterina Charkova'\n",
      "Representation of A: [[ 0.636   0.4515 -4.0612  2.2748  3.122  -2.1517 -0.3355  0.0622  0.5851\n",
      "  -0.7621  1.2962  0.9377 -0.7083 -1.3391 -1.9118  2.1137  1.353  -0.0135\n",
      "   0.7485 -0.5312 -0.3957  1.9793  0.6706 -0.5138 -0.5816  0.1241  0.8867\n",
      "  -1.2174 -0.9282 -0.7831  0.9341 -0.3393  2.7399  0.7535 -0.0053  1.434\n",
      "   0.0992 -1.1377 -1.5032  1.2273]]\n",
      "Representation of B: [[ 0.0718  0.3868 -3.5062  1.8548  3.5418 -1.91    0.4717  1.1073  0.427\n",
      "   1.5685  1.2931  2.3809 -0.6956 -2.8216 -0.9996  1.1498  0.3402  0.3267\n",
      "   0.8637 -1.9577 -0.2696  1.545   1.1492 -0.8378  0.1516  0.8528  1.5849\n",
      "  -1.0214 -1.8168  0.1694  1.1356  0.088   1.6198  0.7834 -1.4903  2.3448\n",
      "   1.1858  0.1368 -2.0357 -0.6002]]\n",
      "Similarity: [0.9048]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "def check_similarity(input_a, input_b, model):\r\n",
    "    input_a = np.array(input_a).reshape(1,len(input_a))\r\n",
    "    input_b = np.array(input_b).reshape(1,len(input_b))\r\n",
    "    model(input_a,input_b)\r\n",
    "\r\n",
    "    return model.cosine_similarity\r\n",
    "\r\n",
    "for i in range(100):\r\n",
    "    pred_similarity = check_similarity(governor_seq[i],combination_seq[i],model)\r\n",
    "    print(\"******************\")\r\n",
    "    print(f\"Comparing '{governors_list[i]}' and '{combination_list[i]}'\")\r\n",
    "    print(f\"Similarity: predicted={pred_similarity}, true={match[i]}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 4. 25. 23. 25.  2.  7. 20. 13.  4.  7.  9.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "InvalidArgumentError",
     "evalue": "slice index 1 of dimension 0 out of bounds. [Op:StridedSlice] name: outer_model_2/strided_slice/",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-bece8fa9a6de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mpred_similarity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgovernor_seq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcombination_seq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"******************\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Comparing '{governors_list[i]}' and '{combination_list[i]}'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-43-bece8fa9a6de>\u001b[0m in \u001b[0;36mcheck_similarity\u001b[1;34m(input_a, input_b, model)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0minput_b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_b\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_b\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_a\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_a\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_b\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcosine_similarity\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nlp_tensor\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1028\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1029\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1030\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1032\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\grego\\Documents\\kaggle\\pep_names\\char_level_rnn_with_attention.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[0minput_a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[0minput_b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepr_a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minner_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nlp_tensor\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nlp_tensor\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[1;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[0;32m   1038\u001b[0m       \u001b[0mvar_empty\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m       \u001b[0mpacked_begin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpacked_end\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpacked_strides\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvar_empty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m     return strided_slice(\n\u001b[0m\u001b[0;32m   1041\u001b[0m         \u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m         \u001b[0mpacked_begin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nlp_tensor\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nlp_tensor\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[1;34m(input_, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, var, name)\u001b[0m\n\u001b[0;32m   1211\u001b[0m     \u001b[0mstrides\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mones_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1213\u001b[1;33m   op = gen_array_ops.strided_slice(\n\u001b[0m\u001b[0;32m   1214\u001b[0m       \u001b[0minput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m       \u001b[0mbegin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nlp_tensor\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[1;34m(input, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, name)\u001b[0m\n\u001b[0;32m  10502\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10503\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 10504\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m  10505\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10506\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nlp_tensor\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6895\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6896\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6897\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6898\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6899\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nlp_tensor\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: slice index 1 of dimension 0 out of bounds. [Op:StridedSlice] name: outer_model_2/strided_slice/"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "for i in range(10):\r\n",
    "    print(governor_seq[i])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ 4. 25. 23. 25.  2.  7. 20. 13.  4.  7.  9.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 4. 25. 23. 25.  2.  7. 20. 13.  4.  7.  9.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 4.  4.  6.  8.  5.  2.  8. 19. 14.  3.  5.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 4.  4.  6.  8.  5.  2.  8. 19. 14.  3.  5.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 4.  4.  6.  8.  5.  2.  8. 19. 14.  3.  5.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 4.  4.  6.  8.  5.  2.  8. 19. 14.  3.  5.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 4.  4.  6.  8.  5.  2.  8. 19. 14.  3.  5.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 4.  4.  6.  8.  5.  2.  8. 19. 14.  3.  5.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 4.  4.  6.  8.  5.  2.  8. 19. 14.  3.  5.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 4.  4.  6.  8.  5.  2.  8. 19. 14.  3.  5.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('nlp_tensor': conda)"
  },
  "interpreter": {
   "hash": "fcbba280eac50286b31d8cb86df25696dcc42d5d7558ed290f125a3371417a84"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}